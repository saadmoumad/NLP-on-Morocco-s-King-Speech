{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_based.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaWN7FHAekxX",
        "colab_type": "code",
        "outputId": "0e975176-9ad9-4dd9-f14b-1aacb1e5b8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/gdrive')'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCMDvUCvqhlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLQ4-H_gMY_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/saadmoumad/NLP-on-Morocco-s-King-Speech"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_II4lSJ3MZG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Scraping Discours from maroc.ma \n",
        "!python3 NLP-on-Morocco-s-King-Speech/DiscourScraping.py\n",
        "#Alredy pushed with git-repo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9cc3MJZGdBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukthk_qLF1S8",
        "colab_type": "code",
        "outputId": "dbaa78e2-1970-4238-d4e1-00f85e456a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "#installing Spacy for text preprocessing\n",
        "!pip3 install spacy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hETrNJaB0XNa",
        "colab_type": "code",
        "outputId": "5fc7666e-373f-47b0-fed1-788a31a814a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "#Downloading French model\n",
        "!python -m spacy download fr_core_news_sm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fr_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz#egg=fr_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (47.1.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L17delzxKGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"/usr/local/lib/python3.6/dist-packages/fr_core_news_sm/fr_core_news_sm-2.2.5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLNY5Y7xbAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = 'NLP-on-Morocco-s-King-Speech/Disc_Text'\n",
        "files_name = os.listdir(data_dir)\n",
        "files_name.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7eYdviJ3LGI",
        "colab_type": "code",
        "outputId": "e91d4a0a-c26d-4a70-f3fd-23a16b9a9890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(files_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW0YGjCCP6EN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Passing a Spacy.doc object and returning a list of string Token \n",
        "def get_token_list(doc):\n",
        "    l = []\n",
        "    for token in doc:\n",
        "        l.append(str(token))\n",
        "    return l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNdbDPNFg7ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Return a set objet of unique token in all 'Discours'\n",
        "def get_vocab_set(files_name):\n",
        "    s = set()\n",
        "    for file in files_name[1:]: #exclu .DS_Store file\n",
        "        text = open(os.path.join(data_dir, file), 'rb').read().decode(encoding='utf-8')\n",
        "        doc = nlp(text)\n",
        "        token_list = get_token_list(doc)\n",
        "        s_next = set(token_list)\n",
        "        s = s.union(s_next.difference(s))\n",
        "    return sorted(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgtasbKfg-3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_set = get_vocab_set(files_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-mJieJqhhpM",
        "colab_type": "code",
        "outputId": "f888b561-7898-40bb-c7ca-2ff127fb9dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15701"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QROQou-RioQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert Text (as Tokens) to int\n",
        "def text_as_int(files_name, word2idx):\n",
        "    text_int = []\n",
        "    for file in files_name[1:]: #exclu .DS_Store file\n",
        "          text = open(os.path.join(data_dir, file), 'rb').read().decode(encoding='utf-8')\n",
        "          doc = nlp(text)\n",
        "          token_list = get_token_list(doc)\n",
        "          text_int += [word2idx[word] for word in token_list]\n",
        "    return text_int"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKne4K84hBaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique Token to indices\n",
        "word2idx = {u:i for i, u in enumerate(vocab_set)}\n",
        "idx2word = np.array(vocab_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuS8lvRHj75f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_as_int = np.array(text_as_int(files_name, word2idx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaaGTMJ2j82-",
        "colab_type": "code",
        "outputId": "1d20f405-54cb-4a3a-d6d3-51ceab065e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(text_as_int)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "447294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NmyPcBtlUNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 30\n",
        "examples_per_epoch = len(text_as_int)//(seq_length+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSHNRMPlmEI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4A0fQn7mHtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = words_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boYp6MabmS3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_8Bode8ml5r",
        "colab_type": "code",
        "outputId": "156f857a-2e51-4152-b4fe-c74ec8b47296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "for i in dataset.take(2):\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(30,), dtype=int64, numpy=\n",
            "array([   13,  1368, 14926,   874,    13,  1809,  8944,  1758,  6738,\n",
            "        8944,   653, 13369, 13808,  9000,  1768,    26,  1928,  1026,\n",
            "        6738,  1982,   766, 10756, 14926,  8944, 14193,  8464, 10407,\n",
            "        9984, 14859, 11677])>, <tf.Tensor: shape=(30,), dtype=int64, numpy=\n",
            "array([ 1368, 14926,   874,    13,  1809,  8944,  1758,  6738,  8944,\n",
            "         653, 13369, 13808,  9000,  1768,    26,  1928,  1026,  6738,\n",
            "        1982,   766, 10756, 14926,  8944, 14193,  8464, 10407,  9984,\n",
            "       14859, 11677,    26])>)\n",
            "(<tf.Tensor: shape=(30,), dtype=int64, numpy=\n",
            "array([ 1928,  1419,  9000,  1873,  1155,  1189,    26, 11787,   874,\n",
            "        9215,  6583,  5320, 13413,  8295,  1495,    26, 11018,  4414,\n",
            "        9000,  8969,  5320,  8944,  7547,  1435,  2191,    26,  9997,\n",
            "       13410,  7751,  5320])>, <tf.Tensor: shape=(30,), dtype=int64, numpy=\n",
            "array([ 1419,  9000,  1873,  1155,  1189,    26, 11787,   874,  9215,\n",
            "        6583,  5320, 13413,  8295,  1495,    26, 11018,  4414,  9000,\n",
            "        8969,  5320,  8944,  7547,  1435,  2191,    26,  9997, 13410,\n",
            "        7751,  5320, 14419])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgatnrBtmxNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMclr9v2m8B1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the Tokens vocab\n",
        "vocab_size = len(vocab_set)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2IA-HyHnOEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hAyjOePnUsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab_set),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB922EZ5nW2t",
        "colab_type": "code",
        "outputId": "320dceb7-1d95-4348-e97c-656baa86bea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (32, None, 256)           4019456   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (32, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (32, None, 15701)         16093525  \n",
            "=================================================================\n",
            "Total params: 24,051,285\n",
            "Trainable params: 24,051,285\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAVtIDmWncmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t68xAFddnjwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checkpoints for model training\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "islDGonbnmt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RvDfkEgnqEU",
        "colab_type": "code",
        "outputId": "fcac7bc8-66fe-4147-cc21-8755ad7d0335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "#fit Data to model\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "450/450 [==============================] - 53s 119ms/step - loss: 6.2119\n",
            "Epoch 2/20\n",
            "450/450 [==============================] - 53s 117ms/step - loss: 5.2796\n",
            "Epoch 3/20\n",
            "450/450 [==============================] - 53s 118ms/step - loss: 4.8994\n",
            "Epoch 4/20\n",
            "450/450 [==============================] - 53s 118ms/step - loss: 4.2236\n",
            "Epoch 5/20\n",
            "450/450 [==============================] - 54s 119ms/step - loss: 3.7160\n",
            "Epoch 6/20\n",
            "450/450 [==============================] - 53s 118ms/step - loss: 3.2289\n",
            "Epoch 7/20\n",
            "450/450 [==============================] - 53s 118ms/step - loss: 2.7709\n",
            "Epoch 8/20\n",
            "450/450 [==============================] - 53s 119ms/step - loss: 2.3841\n",
            "Epoch 9/20\n",
            "450/450 [==============================] - 53s 118ms/step - loss: 2.0789\n",
            "Epoch 10/20\n",
            "450/450 [==============================] - 53s 117ms/step - loss: 1.8388\n",
            "Epoch 11/20\n",
            "450/450 [==============================] - 53s 117ms/step - loss: 1.6509\n",
            "Epoch 12/20\n",
            "450/450 [==============================] - 53s 118ms/step - loss: 1.5007\n",
            "Epoch 13/20\n",
            "450/450 [==============================] - 53s 119ms/step - loss: 1.3842\n",
            "Epoch 14/20\n",
            "450/450 [==============================] - 53s 118ms/step - loss: 1.2863\n",
            "Epoch 15/20\n",
            "450/450 [==============================] - 53s 118ms/step - loss: 1.2112\n",
            "Epoch 16/20\n",
            "450/450 [==============================] - 53s 119ms/step - loss: 1.1478\n",
            "Epoch 17/20\n",
            "450/450 [==============================] - 54s 119ms/step - loss: 1.0934\n",
            "Epoch 18/20\n",
            "450/450 [==============================] - 53s 118ms/step - loss: 1.0499\n",
            "Epoch 19/20\n",
            "450/450 [==============================] - 53s 118ms/step - loss: 1.0125\n",
            "Epoch 20/20\n",
            "450/450 [==============================] - 53s 119ms/step - loss: 0.9815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nrk2OdeECST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Rebuild with diff batch size and restore the weights from the latest checkpoint.\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umtz3SikEK05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  doc = nlp(start_string)\n",
        "  start_token = get_token_list(doc)\n",
        "  num_generate = 1000\n",
        "\n",
        "  input_eval = [word2idx[s] for s in start_token]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "  temperature = 1.0\n",
        "  model.reset_states()\n",
        "  \n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "      # using a categorical distribution to predict the token returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "      text_generated.append(idx2word[predicted_id])\n",
        "\n",
        "  return (start_string + ' '.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8GDnJSZFGje",
        "colab_type": "code",
        "outputId": "c4af093a-f1d5-4804-ed62-a86d8514f9d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "print(generate_text(model, start_string=u\"SM le Roi\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SM le RoiMohammed VI , que Dieu L' assiste , a adressé samedi un discours à la Nation à l’ occasion de la Fête du Trône , qui coïncide cette année avec le 17-ème pour exprimer mes sincères remerciements et ma considération à l’ organisation et ce faire en son sein de l' environnement et du développement , nous nous pouvons en nous engageons ensemble et dans le cadre de l' Initiative que Nous source de production , en prenant les délais les plus ouvertes . \n",
            " C' est pourquoi Nous ne cessons d' exprimer , des négociations qui ont été adoptées . \n",
            " Nous exprimons également ces fondations à la concertation , aux organisations de la société civile , sous l’ impulsion du secteur public dans notre pays . A ce titre , Nous est déterminé à renforcer et à veiller résolument sur la régionalisation avancée , dans la mesure où les progrès sont reconnus au voisinage sont un cadre pour les doter d' entre eux , et le soutien public et le développement social de notre pays . \n",
            " Mes frères Chefs d’ Etat auront l’ occasion aujourd’hui aujourd’hui , aujourd’hui , de nous inspirer de vie active et l' immunisation du paysage euro - méditerranéen . \n",
            " Nous réaffirmons que la mise en place de l' Agence s' est ici contredit les manœuvres à de servir le citoyen , en veillant à ce que les préjudices du passé soient réparés et les blessures pansées . Nous adopterons , à cette fin , Nous invitons le gouvernement à établir un plan , voire pour cette réforme . \n",
            " Dans la mesure où l' on ne peut concevoir les objectifs en développement économique et sociale , qui ont besoin aux sacrifices que par les Etats maghrébins , l' élaboration d' un véritable sens démocratique d' une régionalisation naissante à l’ Afrique mérite par le Chef de l’ ouverture qu' Mon regretté Père , feu Leurs Majestés les Rois Mohammed V et Hassan II , bénie soit leur âme . \n",
            " Nous assurons de toute Notre considération et Notre sollicitude , dont les Marocains sont autant investis , les autorités qui ont peu que vous qui vise à mettre au service de nos nations , et pour que les ambitions affichées sont légitimes , nos provinces du sud et les fidèles sujets qui n’ doivent pas perdre de tension . \n",
            " Il s’ agit de cette tribune cette initiative du baccalauréat est une plus grande crédibilité de notre modèle de développement économique et social soutenu aussi bien voulu Me réserver , Majesté , de tout mettre sur la pauvreté et l' exclusion . Le terrorisme n' est pas plus de raison pour mettre un terme à leur occupation ? \n",
            " All rights reserved 2020 \n",
            " \" Louange à DieuPrière et Salut sur le Prophète , Sa famille et ses Compagnons . \n",
            " Majestés , Excellences , Altesses , \n",
            " Nous en avons également un changement auquel le tourisme des moyens de la Fondation Mohammed V pour la poursuite de la loi et les magistrats , confiance dans l' exercice de son exécution et de larges consultations sur les deux Chambres du parlement . Mais Nous pourrons apporter , tout en Notre qualité de Président du Groupe des 77 , plus que , tout comme enseignants Notre Organisation intervient dans la force que traversent les grandes orientations que le Maroc , imprégné de sa souveraineté et de son refus unanime , et pour l' essentiel d' un effort collectif dans le domaine des entreprises . \n",
            " Axe IV : L' importance du combat Royal : \" gestion générale reste des projets qu’ elle induit et qui Nous est propre à dire , a même acte que Nous puis en la Conférence . Bali , pourront se faire une nation et animée plus lorsqu’ ensemble du peuple palestinien , sur ses droits et ses devoirs , à s' sens et de toute la lettre de Notre concept et de la justice pour la paix et le développement , jouissant de la légalité internationale , tant en initiant des prestations bancaires et d’ identifier les faiblesses qui les Marocains . Nous avons veillé à ce que cette réunion se fait dans sa politique comme un pays avec le Royaume . Il convient aussi d' accélérer l' élaboration d' une véritable rupture bilatérales paysage politique autour d' élections libres et nationaux , dans le cadre de l' unanimité nationale sans faille autour de la question , qu' il s' agit , dans une composition et un environnement libre , où la solidarité constante , avec la même détermination , le Maroc appelle de ses voeux un succès de ce traitement de procéder à une nouvelle conscience onusienne aux Nations Unies , à notre peuple représentatives , d' unie , de corps ou de terrorisme , unies , entre autres femmes qui persistent à toute discrimination , son Premier Serviteur était Prince Héritier , et eu égard aux éléments fondamentaux qui l' unissent , au mépris du projet de valeureux lui confère à notre peuple fier d’ assumer pleinement ses responsabilités , à commencer par la crédibilité , grâce à la réussite qui est sans la patrie des interventions , ainsi que n’ est pas traité de droit économique . Cette situation se doit de répondre aux exigences de les peuples du Sud de la Méditerranée , ainsi que , de façon utile et crédible , nos peuples arabes qui persistent à la création de cette occasion , je tiens à souligner que la sécurité et la stabilité du monde sont menacées . Il se doit également faire avancer résolument les traduire des comptes qu’ ils n' attachent nullement commune alors que persévérer sur ces provinces qui vivent la réhabilitation de l' Amazighité et de Notre politique . Vous devez , donc , assumer , une nouvelle occasion , qui est sans cesse renouvelée , le Maroc et la plénitude de ses droits légitimes , il est\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIGdIN1XFMNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}